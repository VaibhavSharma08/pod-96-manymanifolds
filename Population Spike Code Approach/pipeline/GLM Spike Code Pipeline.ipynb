{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pluralistic Approach to Decoding Motor Activity from Different Regions in the Rodent Brain\n",
    "##### Project Contributors: Narotam Singh, Vaibhav, Rishika Mohanta, Prakriti Nayak\n",
    "\n",
    "##### Done as part of [Neuromatch Academy](https://github.com/NeuromatchAcademy/course-content) July 13-31 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Spike Code Approach Pipeline\n",
    "\n",
    "The original data is from Steinmetz, Nicholas A., et al. \"Distributed coding of choice, action and engagement across the mouse brain.\" Nature 576.7786 (2019): 266-273. It was then further cleaned to consider only recordings from motor related areas with more than 50 neurons from atleast 2 mice. We only considered the the open loop condition ie. data between stimulus onset and go cue to avoid representations of moving stimulus from appearing in the neural data we are analysing. \n",
    "\n",
    "We implemented a General Linear Model with Spiking History pipeline in ``python 3.6`` to decode the motor output (``wheel``) from the neural spike data from 50 randomly sampled neurons from 100 randomly sampled trials from different (Session, Brain Area) pairs. We implemented this using Cross Validated Ridge Regressor in the ``scikit-learn`` package.  The length of the temporal kernel ie. the spiking history required for the decoding models to decode optimally can vary from region to region. So we evaluate different kernel sizes between 50 to 250ms and choose the optimal kernel size for analysis.\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression,SGDRegressor,RidgeCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "from numpy.random import default_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = np.load('../cleaned_dataset/train.npz', allow_pickle=True)['arr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions for Random Sample, Temporal History Transformation, and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for Random Sampling of neurons and trials with train-test split\n",
    "def sampler(data, N = 50, Train_N = 80, Test_N = 20, brain_region = None):  ## Samples for each Session\n",
    "  rng = default_rng()\n",
    "  trial_index = rng.choice(data['spks'].shape[1], size=100, replace=False)\n",
    "  if brain_region:\n",
    "    data_temp = data['spks'][data['brain_area']==brain_region,:,:]\n",
    "  else:\n",
    "    data_temp = data['spks']\n",
    "  neuron_index = rng.choice(data_temp.shape[0], size=50, replace=False)\n",
    "  train_trial_index = trial_index[0:Train_N]\n",
    "  test_trial_index = trial_index[Train_N:-1 ]\n",
    "  return neuron_index, train_trial_index, test_trial_index\n",
    "\n",
    "## Function for returning the relevant Trial Data\n",
    "def get_relevant_trial(data, neuron_idx, idx, start, end):\n",
    "    motion = data[\"wheel\"][0][idx]\n",
    "    spikes = data[\"spks\"][neuron_idx, idx,:]\n",
    "    return spikes[:,start:end], motion[start:end]\n",
    "\n",
    "## Function for Transforming Spiking Timeseries to Temporal History Data with d*10 ms kernels\n",
    "def designmatrix(X,d=20):\n",
    "   #print(X.shape)\n",
    "   padded_stim = np.column_stack((np.zeros((X.shape[0],d-1)),X))\n",
    "   X_design = np.zeros((X.shape[1],d*X.shape[0]))\n",
    "   for t in range(X.shape[1]):\n",
    "     X_design[t] = padded_stim[:,t:t+d].flatten()\n",
    "   return np.column_stack((np.ones(X.shape[1]),X_design))\n",
    "\n",
    "## Function for training given session data\n",
    "def train_loop(data, neuron_index, train_trial_index, test_trial_index, d = 10, select_motion = True):\n",
    "  start = int(data[\"stim_onset\"]/data[\"bin_size\"])\n",
    "  model = RidgeCV()#SGDRegressor(penalty='l2')\n",
    "  \n",
    "  X_train,y_train = [],[]\n",
    "  for idx in train_trial_index:\n",
    "    end = int((data[\"stim_onset\"]+data[\"gocue\"][idx])/data[\"bin_size\"])\n",
    "    X_train_part, y_train_part = get_relevant_trial(data, neuron_index, idx, start, end)\n",
    "    X_train_part = designmatrix(X_train_part,d = d)\n",
    "    X_train.append(X_train_part)\n",
    "    y_train.append(y_train_part)\n",
    "  \n",
    "  X_train = np.concatenate(X_train)\n",
    "  y_train = np.concatenate(y_train)  \n",
    "  model.fit(X_train,y_train)\n",
    "  y_pred = model.predict(X_train)\n",
    "  r2_value_train = r2_score(y_train, y_pred)\n",
    "  rvalue_train = linregress(y_train,y_pred).rvalue\n",
    "\n",
    "  X_test,y_test = [],[]\n",
    "  for idx in test_trial_index:\n",
    "    end = int((data[\"stim_onset\"]+data[\"gocue\"][idx])/data[\"bin_size\"])\n",
    "    X_test_part, y_test_part = get_relevant_trial(data, neuron_index, idx, start, end)\n",
    "    X_test_part = designmatrix(X_test_part,d = d)  \n",
    "    X_test.append(X_test_part)\n",
    "    y_test.append(y_test_part)\n",
    "    \n",
    "  X_test = np.concatenate(X_test)\n",
    "  y_test = np.concatenate(y_test)  \n",
    "  y_pred = model.predict(X_test)\n",
    "  r2_value = r2_score(y_test, y_pred)\n",
    "  rvalue = linregress(y_test,y_pred).rvalue\n",
    "\n",
    "  return model, r2_value, rvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the Data to Analyze\n",
    "Here we go through the cleaned data and summarize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(alldata)):\n",
    "  dat = alldata[i]\n",
    "  print(f\"index {i}  brain areas {set(dat['brain_area'])} Neurons {dat['spks'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running GLM analysis for all (Session, Brain Area) pairs and find optimal kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "result = []\n",
    "for jj in tqdm(range(3)):\n",
    "  result = []\n",
    "  for i in range(len(alldata)):\n",
    "    dat = alldata[i]\n",
    "    ba = set(dat['brain_area'])\n",
    "    for bb in ba:\n",
    "      neuron_index, train_trial_index, test_trial_index = sampler(dat, brain_region = bb)\n",
    "      \n",
    "      # Finding optimal 'd' for every brain region.\n",
    "      best_d, best_coff, best_r2 = -1, 0, -np.inf\n",
    "      \n",
    "      for d in range(6, 25):\n",
    "        #neuron_index, train_trial_index, test_trial_index = sampler(dat, brain_region = bb)\n",
    "        try:\n",
    "          model, r2, corr_coeff = train_loop(dat, neuron_index, train_trial_index, test_trial_index, d)\n",
    "        except:\n",
    "          pass\n",
    "        if r2 > best_r2 :\n",
    "          best_d, best_r2 = d, r2\n",
    "\n",
    "      for _ in range(10):\n",
    "        neuron_index, train_trial_index, test_trial_index = sampler(dat, brain_region = bb)\n",
    "        try:\n",
    "          model, r2, corr_coeff = train_loop(dat, neuron_index, train_trial_index, test_trial_index, best_d)\n",
    "          result.append([jj, i, bb, best_d, [neuron_index], [train_trial_index], [test_trial_index], model, corr_coeff ,r2])\n",
    "                  \n",
    "        except:\n",
    "          pass\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = [\"Exp_No\",\"#Session_Number\", \"Brain_Areas\", \"Optimal_d\", \"#Neurons_Used\",\"Train_index\", \"Test_index\", \"Model\", \"Correlation_Coefficient\",\"R2_score\"]\n",
    "\n",
    "df.to_csv('../results/result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
